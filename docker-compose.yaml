# Named volumes for persistent data storage
volumes:
  mysql-data:
    labels:
      com.docker.stack.namespace: zoo-database
  redis-data:
    labels:
      com.docker.stack.namespace: zoo-database
  alert-manager-data:
    labels:
      com.docker.stack.namespace: zoo-monitoring
  grafana-data:
    labels:
      com.docker.stack.namespace: zoo-monitoring
  jaeger-data:
    labels:
      com.docker.stack.namespace: zoo-monitoring
  loki-data:
    labels:
      com.docker.stack.namespace: zoo-monitoring
  prometheus-data:
    labels:
      com.docker.stack.namespace: zoo-monitoring
  promtail-data:
    labels:
      com.docker.stack.namespace: zoo-monitoring


# Shared network between the containers
networks:
  zoo:
    driver: bridge

services:


  # Alert Manager
  zoo-alert-manager:
    image: ghcr.io/intelligent002/zoo/zoo-alert-manager:latest
    command:
      - --config.file=/etc/alertmanager/config.yml
    depends_on:
      zoo-prometheus:
        condition: service_healthy
        restart: true
    healthcheck:
      # Test availability of Alert Manager service, listening & actually serving
      interval: 60s
      retries: 3
      start_period: 10s
      test: [ "CMD-SHELL", "curl -f http://localhost:9093/-/healthy || exit 1" ]
      timeout: 10s
    networks:
      - zoo
    ports:
      - "9093:9093"
    restart: always
    volumes:
      - ./zoo-alert-manager/alertmanager.yml:/etc/alertmanager/config.yml
      - alert-manager-data:/alertmanager

  # cAdvisor for container metrics
  zoo-cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    networks:
      - zoo
    ports:
      - "8081:8080"
    restart: always
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /sys:/sys
      - /proc:/proc
      - /var/lib/docker:/var/lib/docker:ro
      - /data/docker:/data/docker:ro

  # Grafana
  zoo-grafana:
    image: ghcr.io/intelligent002/zoo/zoo-grafana:latest
    depends_on:
      zoo-prometheus:
        condition: service_healthy
        restart: false
      zoo-loki:
        condition: service_healthy
        restart: false
    env_file:
      - .env
    healthcheck:
      # Test availability of Grafana service, listening & actually serving
      interval: 60s
      retries: 3
      start_period: 3s
      test: [ "CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1" ]
      timeout: 10s
    # image: grafana/grafana:11.2.2
    networks:
      - zoo
    ports:
      - "3000:3000"
    restart: always
    volumes:
      - grafana-data:/var/lib/grafana

  # Jaeger
  zoo-jaeger:
    image: ghcr.io/intelligent002/zoo/zoo-jaeger:latest
    healthcheck:
      # Test availability of Jaeger service, listening & actually serving
      interval: 60s
      retries: 3
      start_period: 3s
      test: [ "CMD-SHELL", "curl -f http://localhost:16686 || exit 1" ]
      timeout: 10s
    networks:
      - zoo
    ports:
      - "6831:6831/udp"
      - "16686:16686"
    restart: always
    volumes:
      - jaeger-data:/tmp

  # Loki
  zoo-loki:
    image: ghcr.io/intelligent002/zoo/zoo-loki:latest
    command:
      - --config.file=/etc/loki/local-config.yaml
    healthcheck:
      # Test availability of Loki service, listening & actually serving
      interval: 60s
      retries: 3
      start_period: 10s
      test: [ "CMD-SHELL", "curl -f http://localhost:3100/ready || exit 1" ]
      timeout: 10s
    networks:
      - zoo
    ports:
      - "3100:3100"
    restart: always
    volumes:
      - ./zoo-loki/local-config.yaml:/etc/loki/local-config.yaml
      - loki-data:/loki

  # MySQL Service
  zoo-mysql:
    entrypoint: [ "/bin/bash", "-c", "chmod +x /mysql-health.sh && docker-entrypoint.sh mysqld" ]
    env_file:
      - .env
    healthcheck:
      # Test availability of mysql service, listening & actually serving - via mounted script
      interval: 60s
      retries: 3
      start_period: 3s
      test: [ "CMD", "/mysql-health.sh" ]
      timeout: 10s
    image: mysql:8.0
    networks:
      - zoo
    ports:
      - "3307"
    restart: always
    volumes:
      - mysql-data:/var/lib/mysql
      - ./zoo-mysql/mysql-health.sh:/mysql-health.sh

  # MySQL Service exporter for Prometheus
  zoo-mysqld-exporter:
    image: ghcr.io/intelligent002/zoo/zoo-mysqld-exporter:latest
    command:
      - '--mysqld.address=zoo-mysql:3307'
      - '--web.listen-address=:3308'
    depends_on:
      zoo-mysql:
        condition: service_healthy
        restart: true
    healthcheck:
      # Test availability of MySQLd Exporter service, listening & actually serving
      interval: 60s
      retries: 3
      start_period: 10s
      test: [ "CMD-SHELL", "response=$$(curl -s http://localhost:3308/metrics | grep '^mysql_up ' | awk '{print $$2}'); \
                  if [ \"$$response\" != \"1\" ]; then echo \"Status is not OK\" && exit 1; else echo \"Status is OK\" && exit 0; fi" ]
      timeout: 10s
    networks:
      - zoo
    ports:
      - "3308:3308"
    volumes:
      - ./zoo-mysqld-exporter/my.cnf:/.my.cnf

  # Node Exporter
  zoo-node-exporter:
    image: ghcr.io/intelligent002/zoo/zoo-node-exporter:latest
    healthcheck:
      # Test availability of Node Exporter service, listening & actually serving
      interval: 60s
      retries: 3
      start_period: 10s
      test: [ "CMD-SHELL", "curl -f http://localhost:9100/metrics || exit 1" ]
      timeout: 10s
    networks:
      - zoo
    ports:
      - "9100:9100"
    restart: always


  # Backend written in PHP/Laravel (php:8.2-fpm)
  zoo-php-laravel:
    image: ghcr.io/intelligent002/zoo/zoo-php-laravel:latest
    command: [ "/bin/sh", "-c", "set -e && /mysql-wait.sh && php artisan migrate --force && php-fpm" ]
    depends_on:
      zoo-mysql:
        condition: service_healthy
        restart: false
      zoo-redis:
        condition: service_healthy
        restart: false
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
    environment:
      - APP_PORT=8103
      - APP_URL=http://localhost:8003/
      - DB_DATABASE=zoo-db
      - DB_HOSTNAME=zoo-mysql
      - DB_PASSWORD=zoo-pass
      - DB_PORT=3307
      - DB_USERNAME=zoo-user
      - ENVIRONMENT=DEVELOPMENT
      - LOG_LEVEL=debug
      - REDIS_BASE=0
      - REDIS_HOST=zoo-redis
      - REDIS_PASSWORD=zoo-pass
      - REDIS_PORT=6379
      - REDIS_USERNAME=zoo-user
      - SERVICE_NAME=zoo-php-laravel
    expose:
      - "8103"
    healthcheck:
      # Test availability of php-fpm service, listening & serving - via inline cgi-fcgi request parsed by JQ
      interval: 60s
      retries: 3
      start_period: 3s
      test: [ "CMD-SHELL", "response=$$(REQUEST_URI=/health/liveness SCRIPT_FILENAME=/var/www/html/public/index.php \
                  REQUEST_METHOD=GET cgi-fcgi -bind -connect 127.0.0.1:8103 | sed -n '/^{/,$$p' | jq -r '.status'); \
                  if [ \"$$response\" != \"OK\" ]; then echo \"Status is not OK\" && exit 1; else echo \"Status is OK\" && exit 0; fi" ]
      timeout: 10s
    networks:
      - zoo
    restart: always

  # NGINX Service (Reverse Proxy + HTTP to PHP-FPM converter + Static File Serving)
  zoo-php-laravel-http2fpm:
    image: ghcr.io/intelligent002/zoo/zoo-php-laravel-http2fpm:latest
    depends_on:
      zoo-php-laravel:
        condition: service_healthy
        restart: false
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
    environment:
      - ENVIRONMENT=DEVELOPMENT
      - LOG_LEVEL=debug
      - NGINX_PORT=8104
      - SERVICE_NAME=zoo-php-laravel-http2fpm
      - ZOO_PHP_LARAVEL_PORT=8103
    labels:
      - "traefik.http.services.zoo-php-laravel-http2fpm.loadbalancer.server.port=8104"
      - "traefik.http.routers.zoo-php-laravel-http2fpm.rule=Host(`private-api.docker.r7g.org`)"
      - "traefik.http.routers.zoo-php-laravel-http2fpm.entrypoints=web"
      #- "traefik.http.routers.zoo-php-laravel-http2fpm.middlewares=redirect-to-https"
      #- "traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https"
      #- "traefik.http.routers.zoo-php-laravel-http2fpm-secure.rule=Host(`zoo-php-laravel-http2fpm.docker.r7g.org`)"
      #- "traefik.http.routers.zoo-php-laravel-http2fpm-secure.entrypoints=websecure"
      #- "traefik.http.routers.zoo-php-laravel-http2fpm-secure.tls.certresolver=myresolver"
    expose:
      - "8104"
    healthcheck:
      # Test availability of nginx service, listening & serving - via inline curl request parsed by JQ
      interval: 60s
      retries: 3
      start_period: 3s
      test: [ "CMD-SHELL", "response=$$(curl -s http://localhost:8104/liveness | jq -r '.status'); \
                  if [ \"$$response\" != \"OK\" ]; then echo \"Status is not OK\" && exit 1; else echo \"Status is OK\" && exit 0; fi" ]
      timeout: 10s
    networks:
      - zoo
    restart: always
    volumes:
      - ./zoo-php-laravel-http2fpm/probe/:/var/www/html/

  # Prometheus
  zoo-prometheus:
    image: ghcr.io/intelligent002/zoo/zoo-prometheus:latest
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --web.enable-lifecycle
      - --storage.tsdb.retention.time=15d
      - --storage.tsdb.retention.size=5GB
    healthcheck:
      # Test availability of Prometheus service, listening & actually serving
      interval: 60s
      retries: 3
      start_period: 3s
      test: [ "CMD-SHELL", "curl -f http://localhost:9090/-/healthy || exit 1" ]
      timeout: 10s
    networks:
      - zoo
    ports:
      - "9091:9090"
    restart: always
    volumes:
      - ./zoo-prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./zoo-prometheus/rules/:/etc/prometheus/rules/
      - prometheus-data:/prometheus


  # Promtail
  zoo-promtail:
    image: ghcr.io/intelligent002/zoo/zoo-promtail:latest
    command:
      - --config.file=/etc/promtail/promtail-config.yml
    depends_on:
      zoo-loki:
        condition: service_healthy
        restart: true
    healthcheck:
      # Test availability of Promtail service, listening & actually serving
      interval: 60s
      retries: 3
      start_period: 10s
      test: [ "CMD-SHELL", "curl -f http://localhost:9080/ready || exit 1" ]
      timeout: 10s
    networks:
      - zoo
    ports:
      - "9080:9080"
    restart: always
    volumes:
      - ./zoo-promtail/promtail-config.yml:/etc/promtail/promtail-config.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/log:/var/log:ro
      - promtail-data:/tmp

  # Backend written in Python/Flask (python:3.12.5-alpine3.20)
  zoo-python-flask:
    image: ghcr.io/intelligent002/zoo/zoo-python-flask:latest
    depends_on:
      zoo-mysql:
        condition: service_healthy
        restart: true
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
    environment:
      - APP_PORT=8100
      - DB_DATABASE=zoo-db
      - DB_HOSTNAME=zoo-mysql
      - DB_PASSWORD=zoo-pass
      - DB_PORT=3307
      - DB_USERNAME=zoo-user
      - DEBUG_MODE=False
      - ENVIRONMENT=DEVELOPMENT
      - LOG_LEVEL=DEBUG
      - SERVICE_NAME=zoo-python-flask
    expose:
      - "8100"
    healthcheck:
      # Test availability of gunicorn service, listening & serving - via inline curl request parsed by JQ
      interval: 60s
      retries: 3
      start_period: 3s
      test: [ "CMD-SHELL", "response=$$(curl -s http://localhost:8100/graphql/liveness | jq -r '.status'); \
                  if [ \"$$response\" != \"OK\" ]; then echo \"Status is not OK\" && exit 1; else echo \"Status is OK\" && exit 0; fi" ]
      timeout: 10s
    networks:
      - zoo
    restart: always


  # Backend written in Python/FastAPI (python:3.12.5-alpine3.20)
  zoo-python-fastapi:
    image: ghcr.io/intelligent002/zoo/zoo-python-fastapi:latest
    depends_on:
      zoo-mysql:
        condition: service_healthy
        restart: true
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
    environment:
      - APP_PORT=8101
      - DB_DATABASE=zoo-db
      - DB_HOSTNAME=zoo-mysql
      - DB_PASSWORD=zoo-pass
      - DB_PORT=3307
      - DB_USERNAME=zoo-user
      - DEBUG_MODE=False
      - ENVIRONMENT=DEVELOPMENT
      - LOG_LEVEL=DEBUG
      - SERVICE_NAME=zoo-python-fastapi
    labels:
      - "traefik.http.services.zoo-python-fastapi.loadbalancer.server.port=8101"
      - "traefik.http.routers.zoo-python-fastapi.rule=Host(`public-api.docker.r7g.org`)"
      - "traefik.http.routers.zoo-python-fastapi.entrypoints=web"
      #- "traefik.http.routers.zoo-python-fastapi.middlewares=redirect-to-https"
      #- "traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https"
      #- "traefik.http.routers.zoo-python-fastapi-secure.rule=Host(`zoo-python-fastapi.docker.r7g.org`)"
      #- "traefik.http.routers.zoo-python-fastapi-secure.entrypoints=websecure"
      #- "traefik.http.routers.zoo-python-fastapi-secure.tls.certresolver=myresolver"
    expose:
      - "8101"
    healthcheck:
      # Test availability of uvicorn service, listening & serving - via inline curl request parsed by JQ
      interval: 60s
      retries: 3
      start_period: 3s
      test: [ "CMD-SHELL", "response=$$(curl -s http://localhost:8101/liveness | jq -r '.status'); \
                  if [ \"$$response\" != \"OK\" ]; then echo \"Status is not OK\" && exit 1; else echo \"Status is OK\" && exit 0; fi" ]
      timeout: 10s
    networks:
      - zoo
    restart: always

  # Redis for PHP Metrics and other usages
  zoo-redis:
    image: ghcr.io/intelligent002/zoo/zoo-redis:latest
    env_file:
      - .env
    healthcheck:
      # Test availability of Redis service, listening & serving - via inline redis-cli request
      interval: 60s
      retries: 3
      start_period: 3s
      test: [ "CMD-SHELL", "response=$$(redis-cli -u redis://default:zoo-pass@127.0.0.1:6379 ping); \
                  if [ \"$$response\" != \"PONG\" ]; then echo \"Status is not OK\" && exit 1; else echo \"Status is OK\" && exit 0; fi" ]
      timeout: 10s
    networks:
      - zoo
    ports:
      - "6379:6379"
    restart: always
    volumes:
      - redis-data:/data

# NGINX Service (Routing + Reverse Proxy + Caching + Static File Serving)
#  zoo-router:
#    image: ghcr.io/intelligent002/zoo/zoo-router:latest
#    depends_on:
#      zoo-typescript-angular:
#        condition: service_healthy
#        restart: false
#      zoo-typescript-react:
#        condition: service_healthy
#        restart: false
#      zoo-python-flask:
#        condition: service_healthy
#        restart: false
#      zoo-php-laravel-http2fpm:
#        condition: service_healthy
#        restart: false
#    environment:
#      - ENVIRONMENT=DEVELOPMENT
#      - NGINX_PORT=8120
#      - SERVICE_NAME=zoo-router
#      - ZOO_PYTHON_FASTAPI_PORT=8101
#      - ZOO_TYPESCRIPT_REACT_PORT=8102
#      - ZOO_PHP_LARAVEL_HTTP2FPM_PORT=8104
#      - ZOO_TYPESCRIPT_ANGULAR_PORT=8105
#    healthcheck:
#      # Test availability of nginx service, listening & serving - via inline curl request compared as is
#      interval: 60s
#      retries: 3
#      start_period: 3s
#      test: [ "CMD-SHELL", "response=$$(curl -s http://localhost:8120/liveness | jq -r '.status'); \
#                  if [ \"$$response\" != \"OK\" ]; then echo \"Status is not OK\" && exit 1; else echo \"Status is OK\" && exit 0; fi" ]
#      timeout: 10s
#    networks:
#      - zoo
#    ports:
#      - "8120:8120"
#    restart: always
#    volumes:
#      - ./zoo-router/probe/:/var/www/html/

  # Traefik reverse proxy
  zoo-traefik:
    image: traefik:v2.10
    command:
      - "--api.insecure=true"  # Enable Traefik dashboard at :8080 (disable in production)
      - "--providers.docker=true"
      - "--entrypoints.web.address=:80"
      #- "--entrypoints.websecure.address=:443"
      #- "--certificatesresolvers.myresolver.acme.httpchallenge=false"
      #- "--certificatesresolvers.myresolver.acme.httpchallenge.entrypoint=web"
      #- "--certificatesresolvers.myresolver.acme.email=your-email@example.com"
      #- "--certificatesresolvers.myresolver.acme.storage=/letsencrypt/acme.json"
    ports:
      - "80:80"         # HTTP
      #- "443:443"       # HTTPS
      - "8080:8080"     # Traefik dashboard
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
      # - "./letsencrypt:/letsencrypt"
    networks:
      - zoo

  # Frontend written in TypeScript/React (node:20.18.0-alpine3.20)
  zoo-typescript-react:
    image: ghcr.io/intelligent002/zoo/zoo-typescript-react:latest
    depends_on:
      zoo-python-flask:
        condition: service_healthy
        restart: true
    environment:
      - BACKEND_HOSTNAME=http://public-api.docker.r7g.org/graphql
      - ENVIRONMENT=DEVELOPMENT
      - LOG_LEVEL=debug
      - NGINX_PORT=8102
      - SERVICE_NAME=zoo-typescript-react
    labels:
      - "traefik.http.services.zoo-typescript-react.loadbalancer.server.port=8102"
      - "traefik.http.routers.zoo-typescript-react.rule=Host(`public.docker.r7g.org`)"
      - "traefik.http.routers.zoo-typescript-react.entrypoints=web"
      #- "traefik.http.routers.zoo-typescript-react.middlewares=redirect-to-https"
      #- "traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https"
      #- "traefik.http.routers.zoo-typescript-react-secure.rule=Host(`zoo-typescript-react.docker.r7g.org`)"
      #- "traefik.http.routers.zoo-typescript-react-secure.entrypoints=websecure"
      #- "traefik.http.routers.zoo-typescript-react-secure.tls.certresolver=myresolver"
    expose:
      - "8102"
    healthcheck:
      # Test availability of nginx service, listening & serving - via inline curl request parsed by JQ
      interval: 60s
      retries: 3
      start_period: 3s
      test: [ "CMD-SHELL", "response=$$(curl -s http://localhost:8102/liveness | jq -r '.status'); \
                  if [ \"$$response\" != \"OK\" ]; then echo \"Status is not OK\" && exit 1; else echo \"Status is OK\" && exit 0; fi" ]
      timeout: 10s
    networks:
      - zoo
    restart: always

  # Frontend written in TypeScript/angular (node:20.18.0-alpine3.20)
  zoo-typescript-angular:
    image: ghcr.io/intelligent002/zoo/zoo-typescript-angular:latest
    depends_on:
      zoo-php-laravel-http2fpm:
        condition: service_healthy
        restart: false
    environment:
      - BACKEND_HOSTNAME=http://private-api.docker.r7g.org
      - ENVIRONMENT=DEVELOPMENT
      - LOG_LEVEL=debug
      - NGINX_PORT=8105
      - SERVICE_NAME=zoo-typescript-angular
    labels:
      - "traefik.http.services.zoo-typescript-angular.loadbalancer.server.port=8105"
      - "traefik.http.routers.zoo-typescript-angular.rule=Host(`private.docker.r7g.org`)"
      - "traefik.http.routers.zoo-typescript-angular.entrypoints=web"
      #- "traefik.http.routers.zoo-typescript-angular.middlewares=redirect-to-https"
      #- "traefik.http.middlewares.redirect-to-angular.redirectscheme.scheme=https"
      #- "traefik.http.routers.zoo-typescript-angular-secure.rule=Host(`zoo-typescript-angular.docker.r7g.org`)"
      #- "traefik.http.routers.zoo-typescript-angular-secure.entrypoints=websecure"
      #- "traefik.http.routers.zoo-typescript-angular-secure.tls.certresolver=myresolver"
    expose:
      - "8105"
    healthcheck:
      # Test availability of nginx service, listening & serving - via inline curl request parsed by JQ
      interval: 60s
      retries: 3
      start_period: 3s
      test: [ "CMD-SHELL", "response=$$(curl -s http://localhost:8105/liveness | jq -r '.status'); \
                  if [ \"$$response\" != \"OK\" ]; then echo \"Status is not OK\" && exit 1; else echo \"Status is OK\" && exit 0; fi" ]
      timeout: 10s
    networks:
      - zoo
    restart: always
